{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset with 50 samples saved to /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/data/Experiment_Dataset.csv\n",
      "Dataset shape: (50, 18)\n",
      "Successful companies: 10\n",
      "Unsuccessful companies: 40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Since we're in a notebook, we need to set the project root manually\n",
    "# Adjust this path according to your notebook's location relative to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Load the datasets\n",
    "unsuccessful_path = os.path.join(project_root, 'data', 'Merged_Unsuccessful_V2.csv')\n",
    "successful_path = os.path.join(project_root, 'data', 'Merged_Successful_V2.csv')\n",
    "\n",
    "unsuccessful_df = pd.read_csv(unsuccessful_path)\n",
    "successful_df = pd.read_csv(successful_path)\n",
    "\n",
    "# Add a 'success' column to each dataset\n",
    "unsuccessful_df['success'] = 0\n",
    "successful_df['success'] = 1\n",
    "\n",
    "# Randomly sample 40 rows from unsuccessful and 10 from successful\n",
    "unsuccessful_sample = unsuccessful_df.sample(n=40, random_state=42)\n",
    "successful_sample = successful_df.sample(n=10, random_state=42)\n",
    "\n",
    "# Concatenate the samples\n",
    "merged_sample = pd.concat([unsuccessful_sample, successful_sample], ignore_index=True)\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_sample = merged_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the merged sample\n",
    "output_path = os.path.join(project_root, 'data', 'Experiment_Dataset.csv')\n",
    "merged_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merged dataset with 50 samples saved to {output_path}\")\n",
    "print(f\"Dataset shape: {merged_sample.shape}\")\n",
    "print(f\"Successful companies: {merged_sample['success'].sum()}\")\n",
    "print(f\"Unsuccessful companies: {len(merged_sample) - merged_sample['success'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 org_name                              org_uuid  \\\n",
      "0        3080  Mytower  076d86c0-0ddb-414e-a7d1-4021d82e4f95   \n",
      "\n",
      "                                founder_linkedin_url  \\\n",
      "0  https://www.linkedin.com/in/meiri-shemesh-b673...   \n",
      "\n",
      "                                         json_string  \\\n",
      "0  {\"version\": 1, \"hits\": 1, \"results\": 1, \"kgver...   \n",
      "\n",
      "                                     structured_info  \\\n",
      "0  {'name': 'Meiri Shemesh', 'gender': '', 'birth...   \n",
      "\n",
      "                                           paragraph          domain  \\\n",
      "0  Meiri Shemesh is known for their contribution ...  mytowerapp.com   \n",
      "\n",
      "      status founded_on                                      category_list  \\\n",
      "0  operating     1/1/16  Internet of Things,Property Development,Proper...   \n",
      "\n",
      "                     category_groups_list country_code      city  \\\n",
      "0  Internet Services,Real Estate,Software          ISR  Tel Aviv   \n",
      "\n",
      "                                   short_description  \\\n",
      "0  A Unified All-in-One Innovative Property Intel...   \n",
      "\n",
      "                                    long_description  \\\n",
      "0  A Unified All-in-One Innovative Property Manag...   \n",
      "\n",
      "                                     integrated_info  success  \n",
      "0  Organisation's Name: Mytower Founder's Info: M...        0  \n"
     ]
    }
   ],
   "source": [
    "print(merged_sample.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 16:27:43.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-25 16:27:43.565 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-25 16:27:43.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No secrets found. Valid paths for a secrets.toml file or secret directories are: /Users/wangxiang/.streamlit/secrets.toml, /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/experiments/.streamlit/secrets.toml",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_path)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize the StartupFramework\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m framework \u001b[38;5;241m=\u001b[39m \u001b[43mStartupFramework\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Function to flatten nested dictionaries\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_dict\u001b[39m(d, parent_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/ssff_framework.py:17\u001b[0m, in \u001b[0;36mStartupFramework.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarket_agent \u001b[38;5;241m=\u001b[39m \u001b[43mMarketAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_agent \u001b[38;5;241m=\u001b[39m ProductAgent(model)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfounder_agent \u001b[38;5;241m=\u001b[39m FounderAgent(model)\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/agents/market_agent.py:22\u001b[0m, in \u001b[0;36mMarketAgent.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_api \u001b[38;5;241m=\u001b[39m GoogleSearchAPI()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/agents/base_agent.py:13\u001b[0m, in \u001b[0;36mBaseAgent.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_api \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/utils/api_wrapper.py:19\u001b[0m, in \u001b[0;36mOpenAIAPI.__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name  \u001b[38;5;66;03m# E.g., \"gpt-4-0613\" or \"gpt-4-1106-preview\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Try to get the API key from Streamlit secrets, fall back to environment variable\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecrets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY not found in Streamlit secrets or environment variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<frozen _collections_abc>:774\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/streamlit/runtime/secrets.py:491\u001b[0m, in \u001b[0;36mSecrets.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the value with the given key. If no such key\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mexists, raise a KeyError.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03mThread-safe.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[key]\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Mapping):\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/streamlit/runtime/secrets.py:393\u001b[0m, in \u001b[0;36mSecrets._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    388\u001b[0m         secret_error_messages_singleton\u001b[38;5;241m.\u001b[39mget_no_secrets_found_message(\n\u001b[1;32m    389\u001b[0m             file_paths\n\u001b[1;32m    390\u001b[0m         )\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_exception_if_not_suppressed(error_msg)\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m secrets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_set_environment_variable(k, v)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No secrets found. Valid paths for a secrets.toml file or secret directories are: /Users/wangxiang/.streamlit/secrets.toml, /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/experiments/.streamlit/secrets.toml"
     ]
    }
   ],
   "source": [
    "# Since we're in a notebook, we need to set the project root manually\n",
    "# Adjust this path according to your notebook's location relative to the project root\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import os\n",
    "import toml\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust this path to point to your secrets.toml file\n",
    "secrets_path = Path(os.getcwd()).parent / '.streamlit' / 'secrets.toml'\n",
    "\n",
    "# Load secrets\n",
    "if secrets_path.exists():\n",
    "    with open(secrets_path, 'r') as f:\n",
    "        secrets = toml.load(f)\n",
    "    print(f\"Secrets loaded from {secrets_path}\")\n",
    "else:\n",
    "    print(f\"No secrets file found at {secrets_path}\")\n",
    "    secrets = {}\n",
    "\n",
    "# Set secrets as environment variables\n",
    "for key, value in secrets.items():\n",
    "    os.environ[key] = str(value)\n",
    "\n",
    "# Now you can import your framework\n",
    "from ssff_framework import StartupFramework\n",
    "\n",
    "from ssff_framework import StartupFramework\n",
    "\n",
    "# Load the experiment dataset\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "input_path = os.path.join(project_root, 'data', 'Experiment_Dataset.csv')\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Initialize the StartupFramework\n",
    "framework = StartupFramework()\n",
    "\n",
    "# Function to flatten nested dictionaries\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Process each row in the dataset\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing company {index + 1}/{len(df)}\")\n",
    "    \n",
    "    # Prepare startup info string\n",
    "    startup_info_str = f\"\"\"\n",
    "    {row['long_description']}\n",
    "    Founder background: {row['paragraph']}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run analysis\n",
    "    analysis_result = framework.analyze_startup(startup_info_str)\n",
    "    \n",
    "    # Flatten nested dictionaries in the result\n",
    "    flat_result = flatten_dict(analysis_result)\n",
    "    \n",
    "    # Add input data to the result\n",
    "    flat_result['input_description'] = row['long_description']\n",
    "    flat_result['input_founder_background'] = row['paragraph']\n",
    "    flat_result['input_success'] = row['success']\n",
    "    \n",
    "    results.append(flat_result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "output_path = os.path.join(project_root, 'data', 'Experiment_Results.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Analysis complete. Results saved to {output_path}\")\n",
    "print(f\"Total rows processed: {len(results_df)}\")\n",
    "print(f\"Number of columns in result: {len(results_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
